{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install seqeval","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-24T18:58:46.161379Z","iopub.execute_input":"2021-05-24T18:58:46.16178Z","iopub.status.idle":"2021-05-24T18:58:56.978255Z","shell.execute_reply.started":"2021-05-24T18:58:46.161693Z","shell.execute_reply":"2021-05-24T18:58:56.977152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import Sequence, to_categorical\n\nfrom seqeval.metrics import accuracy_score, classification_report, f1_score\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nfrom tensorflow_addons.text import crf_log_likelihood, crf_decode","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:58:56.980685Z","iopub.execute_input":"2021-05-24T18:58:56.98113Z","iopub.status.idle":"2021-05-24T18:59:02.887968Z","shell.execute_reply.started":"2021-05-24T18:58:56.981083Z","shell.execute_reply":"2021-05-24T18:59:02.886988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/entity-annotated-corpus/ner_dataset.csv', sep=\",\", encoding=\"latin1\").fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:02.889352Z","iopub.execute_input":"2021-05-24T18:59:02.889719Z","iopub.status.idle":"2021-05-24T18:59:04.260966Z","shell.execute_reply.started":"2021-05-24T18:59:02.889684Z","shell.execute_reply":"2021-05-24T18:59:04.259913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContextNER:\n\n    def __init__(self, df):\n\n        self.__df = df\n\n        self.all_words = set(df.Word.values)\n        self.all_tags = set(df.Tag.values)\n\n        self.num_words = len(self.all_words) + 2\n        self.num_tags = len(self.all_tags) + 1\n\n        self.sentences = self.__build_sentences()\n        self.max_len = self.__get_maxlen()\n\n        self.__build_Xy()\n        self.__build_parsers()\n        self.__parser_arrays()\n\n    def __get_maxlen(self):\n        return max([len(x) for x in self.sentences]) + 1\n\n    def __build_sentences(self):\n\n        return [x for x in self.__df.groupby('Sentence #').apply(\n            lambda xdef: [x for x in zip(\n                xdef.Word.values,\n                xdef.Tag.values\n            )]\n        )]\n\n    def __build_Xy(self):\n\n        self.__X = [[word for word, __ in value] for value in self.sentences]\n        self.__y = [[tag for __, tag in value] for value in self.sentences]\n\n    def __build_parsers(self):\n\n        self.word2idx = {value: idx + 2 for idx,\n                         value in enumerate(self.all_words)}\n        \n        self.word2idx[\"PAD\"] = 0  # Padding - Preenchimento\n        self.word2idx[\"UNK\"] = 1  # Palavras Desconhecidas\n        \n\n        # Converte um index em Word\n        self.idx2word = {idx: value for value, idx in self.word2idx.items()}\n\n        # Converte Tag em Ã¬ndice\n        self.tag2idx = {value: idx + 1 for idx,\n                        value in enumerate(self.all_tags)}\n        self.tag2idx[\"PAD\"] = 0  # Padding - Preenchimento\n\n        # Converte index em Tag\n        self.idx2tag = {idx: value for value, idx in self.tag2idx.items()}\n\n    def parser2categorical(self, y_pred, y_true):\n\n        pred_tag = [[self.idx2tag[idx] for idx in row] \n                    for row in y_pred]\n        \n        y_true_tag = [[self.idx2tag[idx] for idx in row] \n                      for row in y_true]\n\n        return pred_tag, y_true_tag\n\n    def __parser_arrays(self):\n\n        tmp_X = [[self.word2idx[index] for index in value]\n                 for value in self.__X]\n        \n        tmp_y = [[self.tag2idx[index] for index in value]\n                 for value in self.__y]\n\n        self.X_array = pad_sequences(maxlen=self.max_len,\n                                     sequences=tmp_X,\n                                     padding=\"post\",\n                                     value=0)\n\n        y_pad = pad_sequences(maxlen=self.max_len,\n                              sequences=tmp_y,\n                              padding=\"post\",\n                              value=0)\n\n        self.y_array_normal = y_pad\n        self.y_array = np.array(\n            [to_categorical(index, num_classes=self.num_tags) for index in y_pad])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:04.262377Z","iopub.execute_input":"2021-05-24T18:59:04.26678Z","iopub.status.idle":"2021-05-24T18:59:04.29557Z","shell.execute_reply.started":"2021-05-24T18:59:04.262846Z","shell.execute_reply":"2021-05-24T18:59:04.294132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://github.com/IntelLabs/nlp-architect/blob/5fd26cfb16739aee2f53fe1e913a12a09c8d0404/nlp_architect/nn/tensorflow/python/keras/layers/crf.py#L19\n\nclass CRF(L.Layer):\n    def __init__(self,\n                 output_dim,\n                 sparse_target=True,\n                 **kwargs):\n        \"\"\"    \n        Args:\n            output_dim (int): the number of labels to tag each temporal input.\n            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n        Input shape:\n            (batch_size, sentence length, output_dim)\n        Output shape:\n            (batch_size, sentence length, output_dim)\n        \"\"\"\n        super(CRF, self).__init__(**kwargs)\n        self.output_dim = int(output_dim) \n        self.sparse_target = sparse_target\n        self.input_spec = L.InputSpec(min_ndim=3)\n        self.supports_masking = False\n        self.sequence_lengths = None\n        self.transitions = None\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n        f_shape = tf.TensorShape(input_shape)\n        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n\n        if f_shape[-1] is None:\n            raise ValueError('The last dimension of the inputs to `CRF` '\n                             'should be defined. Found `None`.')\n        if f_shape[-1] != self.output_dim:\n            raise ValueError('The last dimension of the input shape must be equal to output'\n                             ' shape. Use a linear layer if needed.')\n        self.input_spec = input_spec\n        self.transitions = self.add_weight(name='transitions',\n                                           shape=[self.output_dim, self.output_dim],\n                                           initializer='glorot_uniform',\n                                           trainable=True)\n        self.built = True\n\n    def compute_mask(self, inputs, mask=None):\n        # Just pass the received mask from previous layer, to the next layer or\n        # manipulate it if this layer changes the shape of the input\n        return mask\n\n    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n        if sequence_lengths is not None:\n            assert len(sequence_lengths.shape) == 2\n            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n            assert seq_len_shape[1] == 1\n            self.sequence_lengths = K.flatten(sequence_lengths)\n        else:\n            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n                tf.shape(inputs)[1]\n            )\n\n        viterbi_sequence, _ = crf_decode(sequences,\n                                         self.transitions,\n                                         self.sequence_lengths)\n        output = K.one_hot(viterbi_sequence, self.output_dim)\n        return K.in_train_phase(sequences, output)\n\n    @property\n    def loss(self):\n        def crf_loss(y_true, y_pred):\n            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n            log_likelihood, self.transitions = crf_log_likelihood(\n                y_pred,\n                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n                self.sequence_lengths,\n                transition_params=self.transitions,\n            )\n            return tf.reduce_mean(-log_likelihood)\n        return crf_loss\n\n    @property\n    def accuracy(self):\n        def viterbi_accuracy(y_true, y_pred):\n            # -1e10 to avoid zero at sum(mask)\n            mask = K.cast(\n                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n            shape = tf.shape(y_pred)\n            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n            if self.sparse_target:\n                y_true = K.argmax(y_true, 2)\n            y_pred = K.cast(y_pred, 'int32')\n            y_true = K.cast(y_true, 'int32')\n            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n            return K.sum(corrects * mask) / K.sum(mask)\n        return viterbi_accuracy\n\n    def compute_output_shape(self, input_shape):\n        tf.TensorShape(input_shape).assert_has_rank(3)\n        return input_shape[:2] + (self.output_dim,)\n\n    def get_config(self):\n        config = {\n            'output_dim': self.output_dim,\n            'sparse_target': self.sparse_target,\n            'supports_masking': self.supports_masking,\n            'transitions': K.eval(self.transitions)\n        }\n        base_config = super(CRF, self).get_config()\n        return dict(base_config, **config)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:04.301858Z","iopub.execute_input":"2021-05-24T18:59:04.302361Z","iopub.status.idle":"2021-05-24T18:59:04.328158Z","shell.execute_reply.started":"2021-05-24T18:59:04.302286Z","shell.execute_reply":"2021-05-24T18:59:04.327095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_ner = ContextNER(data)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:04.33028Z","iopub.execute_input":"2021-05-24T18:59:04.330786Z","iopub.status.idle":"2021-05-24T18:59:11.684125Z","shell.execute_reply.started":"2021-05-24T18:59:04.330743Z","shell.execute_reply":"2021-05-24T18:59:11.683255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_TRAIN, X_TEST, Y_TRAIN, Y_TEST  = train_test_split(data_ner.X_array,\n                                                     data_ner.y_array, \n                                                     test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:11.687671Z","iopub.execute_input":"2021-05-24T18:59:11.687955Z","iopub.status.idle":"2021-05-24T18:59:11.804354Z","shell.execute_reply.started":"2021-05-24T18:59:11.687928Z","shell.execute_reply":"2021-05-24T18:59:11.803525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_input = tf.keras.layers.Input(shape=(data_ner.max_len,),\n                                       dtype=tf.int32, \n                                       name='sequence_input')\n\nmodel_embedding = tf.keras.layers.Embedding(input_dim=data_ner.num_words,\n                                            output_dim=data_ner.max_len,\n                                            input_length=data_ner.max_len)(sequence_input)\n\nmodel_bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64,\n                                                                  return_sequences=True,\n                                                                  recurrent_dropout=0.1))(model_embedding)\n\nmodel_dropout = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.3))(model_bilstm)\n\nmodel_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(data_ner.num_tags, \n                                                                    activation='relu'))(model_dropout)\nmodel_dense = tf.keras.layers.Dense(data_ner.num_tags, activation='relu')(model_dropout)\n\ncrf_out = CRF(data_ner.num_tags, sparse_target=True)\n\nmodel = tf.keras.Model(inputs=sequence_input, outputs=model_dense)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n              loss='categorical_crossentropy', metrics=['accuracy']\n             )\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:11.805846Z","iopub.execute_input":"2021-05-24T18:59:11.8062Z","iopub.status.idle":"2021-05-24T18:59:14.593859Z","shell.execute_reply.started":"2021-05-24T18:59:11.806166Z","shell.execute_reply":"2021-05-24T18:59:14.593146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\n\nHistory = model.fit(X_TRAIN,\n                    Y_TRAIN,\n                    validation_split=0.1,\n                    batch_size=64, \n                    epochs=15, \n                    shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:59:14.59619Z","iopub.execute_input":"2021-05-24T18:59:14.59678Z","iopub.status.idle":"2021-05-24T19:27:29.160814Z","shell.execute_reply.started":"2021-05-24T18:59:14.596739Z","shell.execute_reply":"2021-05-24T19:27:29.15978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred, y_true = \\\nnp.argmax(model.predict(X_TEST, verbose=1, batch_size=64), axis=-1), \\\nnp.argmax(Y_TEST, -1)\n\npred_tag, true_tag = \\\ndata_ner.parser2categorical(y_pred, y_true) ","metadata":{"execution":{"iopub.status.busy":"2021-05-24T19:27:29.165938Z","iopub.execute_input":"2021-05-24T19:27:29.166368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(pred_tag, true_tag)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(pred_tag, true_tag))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}